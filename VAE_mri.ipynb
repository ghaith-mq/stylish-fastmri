{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VAE_mri",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTMYbec73xrh"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Vanilla_VAE.ipynb\n",
        "Automatically generated by Colaboratory.\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1h9kiwLz1vWd5Lm4m-8Hs3VzjxuzBGjF_\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.utils.data\n",
        "from torch import nn\n",
        "from torch import Tensor\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def re_parameterize(mu: Tensor, log_var: Tensor) -> Tensor:\n",
        "    \"\"\"\n",
        "    Re-parameterization trick to sample from N(mu, var) from\n",
        "    N(0,1).\n",
        "    :param mu: (Tensor) Mean of the latent Gaussian [B x D]\n",
        "    :param log_var: (Tensor) Standard deviation of the latent Gaussian [B x D]\n",
        "    :return: (Tensor) [B x D]\n",
        "    \"\"\"\n",
        "    std = torch.exp(0.5 * log_var)\n",
        "    eps = torch.randn_like(std)\n",
        "    return eps * std + mu \n",
        "\n",
        "def reconstruction_loss(x, x_recon, distribution='gaussian'):\n",
        "    batch_size = x.shape[0]\n",
        "    assert batch_size != 0\n",
        "\n",
        "    if distribution == 'bernoulli':\n",
        "        recon_loss = F.binary_cross_entropy_with_logits(x_recon, x, reduction='sum').div(batch_size)\n",
        "    elif distribution == 'gaussian':\n",
        "        recon_loss = F.mse_loss(x_recon, x, reduction='sum').div(batch_size)\n",
        "    else:\n",
        "        raise ValueError('value error for `distribution` expected: {bernoulli, or gaussian}')\n",
        "\n",
        "    return recon_loss\n",
        "\n",
        "def kl_divergence(mu, log_var):\n",
        "    batch_size = mu.shape[0]\n",
        "    assert batch_size != 0\n",
        "    if mu.data.ndimension() == 4:\n",
        "        mu = mu.view(mu.size(0), mu.size(1))\n",
        "\n",
        "    if log_var.data.ndimension() == 4:\n",
        "        log_var = log_var.view(log_var.size(0), log_var.size(1))\n",
        "\n",
        "    klds = -0.5 * (1 + log_var - mu.pow(2) - log_var.exp())\n",
        "    total_kld = klds.sum(1).mean(0, True)\n",
        "    dimension_wise_kld = klds.mean(0)\n",
        "    mean_kld = klds.mean(1).mean(0, True)\n",
        "\n",
        "    return total_kld, dimension_wise_kld, mean_kld\n",
        "\n",
        "from abc import abstractmethod, ABCMeta\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Encoder(metaclass=ABCMeta):\n",
        "    def __init__(self):\n",
        "        super(Encoder, self).__init__()\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def forward(self, x):\n",
        "        pass\n",
        "\n",
        "\n",
        "class Decoder(metaclass=ABCMeta):\n",
        "    def __init__(self):\n",
        "        super(Decoder, self).__init__()\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def forward(self, x):\n",
        "        pass\n",
        "\n",
        "\n",
        "class Bottleneck(metaclass=ABCMeta):\n",
        "    def __init__(self):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def forward(self, **kwargs):\n",
        "        pass\n",
        "\n",
        "\n",
        "class LossFunction(nn.Module, metaclass=ABCMeta):\n",
        "    def __init__(self):\n",
        "        super(LossFunction, self).__init__()\n",
        "\n",
        "    @abstractmethod\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        pass\n",
        "\n",
        "\n",
        "class View(nn.Module):\n",
        "    def __init__(self, size):\n",
        "        super(View, self).__init__()\n",
        "        self.size = size\n",
        "\n",
        "    def forward(self, tensor):\n",
        "        return tensor.view(self.size)\n",
        "\n",
        "class VanillaVAEEncoder(Encoder, nn.Module):\n",
        "    def __init__(self, z_dim=10, nc=1):\n",
        "        super(VanillaVAEEncoder, self).__init__()\n",
        "        '''\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(nc, 32, 4, 2, 1),  # B,  32, 32, 32\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(32, 32, 4, 2, 1),  # B,  32, 16, 16\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(32, 32, 4, 2, 1),  # B,  32,  8,  8\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(32, 32, 4, 2, 1),  # B,  32,  8,  8\n",
        "            nn.ReLU(True),\n",
        "            View((-1, 32 * 8 * 8)),  # B, 2048\n",
        "            nn.Linear(32 * 8 * 8, 512),  # B, 512\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(512, 256),  # B, 256\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(256, z_dim),  # B, z_dim*2\n",
        "        )\n",
        "        '''\n",
        "        model = torch.hub.load('pytorch/vision:v0.9.0', 'mobilenet_v2').features\n",
        "        model[0][0] = nn.Conv2d(nc, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
        "        model[-1] = nn.Sequential(\n",
        "                    nn.Flatten(),\n",
        "                    nn.Linear(15680, 2048),\n",
        "                    nn.ReLU(True),\n",
        "                    nn.Linear(2048, 1024),\n",
        "                    nn.ReLU(True),\n",
        "                    nn.Linear(1024, 512),\n",
        "                    nn.ReLU(True),\n",
        "                    nn.Linear(512, 256),\n",
        "                    nn.ReLU(True),\n",
        "                    nn.Linear(256, z_dim)\n",
        "                )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.encoder(x)\n",
        "\n",
        "\n",
        "class VanillaVAEDecoder(Decoder, nn.Module):\n",
        "    def __init__(self, z_dim=10, nc=3, target_size=(128, 128)):\n",
        "        super(VanillaVAEDecoder, self).__init__()\n",
        "        self.target_size = target_size\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(z_dim, 256),  # B, 256\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(256, 256),  # B, 256\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(256, 32 * 8 * 8),  # B, 2048\n",
        "            nn.ReLU(True),\n",
        "            View((-1, 32, 8, 8)),  # B,  32,  8,  8\n",
        "            nn.ConvTranspose2d(32, 32, 4, 2, 1),  # B,  32,  8,  8\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(32, 32, 4, 2, 1),  # B,  32, 16, 16\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(32, 32, 4, 2, 1),  # B,  32, 32, 32\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(32, nc, 4, 2, 1),  # B,  nc, 64, 64\n",
        "            nn.Tanh(),\n",
        "            View(self.target_size),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.decoder(x)\n",
        "\n",
        "\n",
        "class VanillaVAEBottleneck(Bottleneck, nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super(VanillaVAEBottleneck, self).__init__()\n",
        "        self.mu = nn.Linear(latent_dim, latent_dim)\n",
        "        self.var = nn.Linear(latent_dim, latent_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        mu = self.mu(x)\n",
        "        log_var = self.var(x)\n",
        "        z = re_parameterize(mu, log_var)\n",
        "        return z, mu, log_var\n",
        "\n",
        "\n",
        "class VanillaVAE(nn.Module):\n",
        "    def __init__(self, z_dim, nc, target_size):\n",
        "        super(VanillaVAE, self).__init__()\n",
        "\n",
        "        self.encoder = VanillaVAEEncoder(z_dim, nc)\n",
        "        self.bottleneck = VanillaVAEBottleneck(z_dim)\n",
        "        self.decoder = VanillaVAEDecoder(z_dim, nc, target_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        z, mu, log_var = self.bottleneck(x)\n",
        "        x = self.decoder(z)\n",
        "        return x, mu, log_var\n",
        "\n",
        "\n",
        "class VanillaVAELossFunction(LossFunction):\n",
        "    def __call__(self, x, x_recon, mu, log_var):\n",
        "        recons_loss = reconstruction_loss(x_recon, x)\n",
        "        total_kld, dim_wise_kld, mean_kld = kl_divergence(mu, log_var)\n",
        "        return recons_loss + total_kld\n"
      ],
      "execution_count": 5,
      "outputs": []
    }
  ]
}